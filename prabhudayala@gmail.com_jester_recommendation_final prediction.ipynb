{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define error metric\n",
    "def _error(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Simple error \"\"\"\n",
    "    return actual - predicted\n",
    "\n",
    "\n",
    "def mae(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Mean Absolute Error \"\"\"\n",
    "    return np.mean(np.abs(_error(actual, predicted)))\n",
    "\n",
    "def nmae(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Normalized Mean Absolute Error \"\"\"\n",
    "    return mae(actual, predicted) / (actual.max() - actual.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved models\n",
    "xgb_svd_model = pickle.load(open('xgb_svd.pickle', 'rb'))\n",
    "svd_model = pickle.load(open('svd.pickle', 'rb'))\n",
    "xgb_bsl_model = pickle.load(open('xgb_bsl.pickle', 'rb'))\n",
    "knn_bsl_u_model = pickle.load(open('knn_bsl_u.pickle', 'rb'))\n",
    "bsl_algo_model = pickle.load(open('bsl_algo.pickle', 'rb'))\n",
    "dataframe = pickle.load(open('dataframe.pickle', 'rb'))\n",
    "train_df_structured = pickle.load(open('train_df_structured.pickle', 'rb'))\n",
    "test_df_structured = pickle.load(open('test_df_structured.pickle', 'rb'))\n",
    "train_df_structured_target = pickle.load(open('train_df_structured_target.pickle', 'rb'))\n",
    "test_df_structured_target = pickle.load(open('test_df_structured_target.pickle', 'rb'))\n",
    "global_model_name = pickle.load(open('global_model_name.pickle', 'rb'))\n",
    "first_best_model = tf.keras.models.load_model('weights-improvement-1.hdf5')\n",
    "min_max_scaler_X = pickle.load(open('min_max_scaler_X.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = random.randint(0,24983)\n",
    "user_id = user_id + 1\n",
    "\n",
    "user_actual_data = dataframe.iloc[user_id]\n",
    "user_actual_rating = user_actual_data.values[1:]\n",
    "\n",
    "data_prepared = [(user_id, i+1 , j) for i,j in enumerate (user_actual_rating)]\n",
    "test_preds_bsl_algo = bsl_algo_model.test(data_prepared)\n",
    "test_preds_bsl_algo = [i.est for i in test_preds_bsl_algo]\n",
    "test_preds_knn_bsl_u = knn_bsl_u_model.test(data_prepared)\n",
    "test_preds_knn_bsl_u = [i.est for i in test_preds_knn_bsl_u]\n",
    "test_preds_svd = svd_model.test(data_prepared)\n",
    "test_preds_svd = [i.est for i in test_preds_svd]\n",
    "user_avg = train_df_structured[train_df_structured['user']==user_id].iloc[0]['user_avg']\n",
    "joke_avg = []\n",
    "for i in range(1,101):\n",
    "    joke_avg.append(train_df_structured[train_df_structured['joke']==i].iloc[0]['joke_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18830800169255246\n",
      "1.02 0.97502613\n",
      "-0.83 0.1457119\n",
      "5.05 0.193254\n",
      "0.58 -1.6425452\n",
      "-9.51 0.28639126\n",
      "5.39 1.4870381\n",
      "2.91 -0.5749135\n",
      "-3.01 -0.7990527\n",
      "0.63 -0.61582327\n",
      "-1.17 1.2790899\n",
      "-0.73 1.8861613\n",
      "5.63 1.6639681\n",
      "-0.83 -2.5672688\n",
      "4.9 1.4790325\n",
      "-1.99 -2.646646\n",
      "-8.3 -4.1257243\n",
      "-3.2 -1.1482968\n",
      "-6.75 -0.75017023\n",
      "-0.19 0.19587278\n",
      "3.64 -1.028048\n",
      "2.91 2.5500631\n",
      "3.2 0.9311142\n",
      "-1.89 0.19923162\n",
      "0.19 -2.4814315\n",
      "3.11 0.45348692\n",
      "4.03 1.2932429\n",
      "2.91 3.4368691\n",
      "-0.58 1.5159049\n",
      "1.31 3.1738338\n",
      "1.99 -0.479012\n",
      "2.38 2.295967\n",
      "2.86 3.4939938\n",
      "2.52 -1.5943074\n",
      "3.4 1.0465555\n",
      "1.65 3.3130112\n",
      "3.74 3.4355044\n",
      "2.52 -1.6247382\n",
      "4.71 1.5095024\n",
      "1.6 1.2082119\n",
      "-0.1 1.1615896\n",
      "-0.34 -0.500937\n",
      "3.98 1.9287496\n",
      "3.98 -0.7464156\n",
      "0.68 -2.5954967\n",
      "3.88 1.1458974\n",
      "5.78 1.390408\n",
      "6.31 1.445859\n",
      "4.95 2.0102682\n",
      "2.04 3.079002\n",
      "5.19 3.8661966\n",
      "1.75 -0.6767192\n",
      "-1.65 -0.3028016\n",
      "4.76 3.1011834\n",
      "4.85 2.9337573\n",
      "1.65 0.36842155\n",
      "3.11 1.88552\n",
      "-3.69 -2.5790772\n",
      "-3.69 -5.1205163\n",
      "1.65 -0.5677285\n",
      "1.94 -0.4739251\n",
      "3.2 2.522922\n",
      "3.69 3.199677\n",
      "3.88 0.27615166\n",
      "3.74 -0.6859298\n",
      "2.09 2.3324027\n",
      "-0.97 2.9923797\n",
      "2.77 -0.75968695\n",
      "2.96 2.9331145\n",
      "2.38 2.7881098\n",
      "2.52 0.57727766\n",
      "-0.58 1.986114\n",
      "-1.02 1.1584015\n"
     ]
    }
   ],
   "source": [
    "user_data_frame = pd.DataFrame()\n",
    "\n",
    "user_data_frame['user_avg'] = user_avg\n",
    "user_data_frame['joke_avg'] = joke_avg\n",
    "user_data_frame['gavg'] = 0.73979\n",
    "user_data_frame['BaselineOnly'] = test_preds_bsl_algo\n",
    "user_data_frame['KnnBaseline_joke'] = test_preds_knn_bsl_u\n",
    "user_data_frame['user_avg'] = user_avg\n",
    "user_data_frame['SVD'] = test_preds_svd\n",
    "user_data_frame['special_feature'] = user_data_frame['user_avg']+user_data_frame['joke_avg']-user_data_frame['gavg']\n",
    "user_data_frame['special_feature_1'] = user_data_frame['special_feature']**2\n",
    "user_data_frame_scaled = min_max_scaler_X.transform(user_data_frame)\n",
    "user_rating_predicted = first_best_model.predict(user_data_frame_scaled)\n",
    "final_user_predicted = []\n",
    "final_user_actual = []\n",
    "for i in range(100):\n",
    "    if(user_actual_rating[i]==99.0):\n",
    "        pass\n",
    "    else:\n",
    "        final_user_predicted.append(user_rating_predicted[i])\n",
    "        final_user_actual.append(user_actual_rating[i])\n",
    "        \n",
    "print(nmae(np.array(final_user_actual), np.array(final_user_predicted)))\n",
    "for i in range(0, len(final_user_predicted)):\n",
    "    print(final_user_actual[i],final_user_predicted[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`As we can see a random user from test data set gives 18% NMAE`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
